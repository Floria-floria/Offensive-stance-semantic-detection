{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16935,"status":"ok","timestamp":1643253678926,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"bv5775L9O7ZN","outputId":"e1cbf8f7-54a3-48d1-8766-686559b1e126"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1643253714865,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"7mtjarWvF4k4","outputId":"d3ec1738-82c0-48f0-9a96-865ddbcf7944"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jan 27 03:21:52 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 释放缓存\n","#!apt install psmisc\n","#!sudo fuser /dev/nvidia*\n","#!kill -9 pid\n","!nvidia-smi "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1643253718111,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"q_bAnvciH-gZ","outputId":"ab8ad99a-3b5a-4e5c-f3a7-d6a60cfd46ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/My Drive/nlp_program\n"]}],"source":["# set path\n","import os\n","os.chdir(\"/content/gdrive/My Drive/nlp_program\")\n","print(os.path.abspath('.'))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12653,"status":"ok","timestamp":1643253732746,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"WSAESbX7UlW2","outputId":"abe4d0f0-d768-49f0-fdf8-10c7cea869fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.4.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from folium) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folium) (1.19.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (2.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2.10)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 1.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 60.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 66.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}],"source":["# install packages\n","!pip install folium\n","!pip3 install torch torchvision\n","!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"coZF50mfD0BM"},"source":["### Roberta"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["28afab1a17be4198adb3de2ea49bff34","911ba88c06a447e2a6d3100a35b8bfca","3d3480c2224f413daa680734d6d8cbe1","2f7595ed850241049a35a3e1a8fc0931","ceba5575677c4132acf2e89da0ae4099","19519b2ac11e408b8d4ab5bf6feff9ba","749264fa8efa4c7fbb6cc1d98794ffd6","8bf199bd414d4d1d890af5a1626ef03c","c3f95541da78493bbf3ef4ce430a27b0","da72526902ef4683aa89d9eb9965fab5","670a568fac82495994a330ecdb64f0f7","d3b883d5280d43f7bb835a8fb1831776","04a5034c9621451c9742d2862e22d0e5","29f3e99c2fbd484bbfc2f69caae97512","f6693d4bd72f472ba1680ecfb02996fc","408b3fc6c2c045f4b04001745926b196","f97917f76466497c8a42c341cf4baadb","1ef29f1edc1d4cd6a5110f55de44d2d3","a9a18fcaa83c4e44b58f636bcd5323d2","82042c072d63457e9c3849d7e8d19c7e","900d4575e28f48ffabc5511d24a99bcb","38a1914c49194598b33e6e471f808463","dfe3cf3b4a1d4e6abb09bb7ee8e1820b","840e5e9e85084f1ebaf764f699128a24","3fdd2080dee146fdafc1a16844120d9c","784aa229669b4e719776499cbc65423e","97f238c6428542e190e69a83ae3855f6","db888624c36a4efb94fc5dc0b4ef5b9f","ea816ad46bcb4960ac42d5322b7b7be0","8d5b0648699c44d0b355a2a643de414d","3786a9827bed4cacb9c434d0b2416577","d8982909a80143088709ca6a5bf0baed","3036522ca17944ee822d9a1b5414516e","2c2c4231c86b40ad8b8da9d1a079522e","337ed3cc8e994556a75fd1301626582a","fa17a8b3e476417d934ef957519cf48a","82a9518bdd8b4d7987c06749ce2a2353","3cc882d6c19e44c699707dd859321a62","93f301b942b14791a2f5cd5202eb5c03","32e54826a0574939bfb1d08adc2bf971","a22567d2d8d94b4b9bed8c01fccbc5a9","e025491975004dcb91c12281fbb28a4b","cd7c64d13f704ee093a797ef5854423e","9ecfbfaaaa8b48c78b3161d4143925bd"]},"executionInfo":{"elapsed":12872,"status":"ok","timestamp":1643253809546,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"IkH9FfCpTRpV","outputId":"ea693808-3c8d-491b-ea91-424c2032900a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28afab1a17be4198adb3de2ea49bff34","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3b883d5280d43f7bb835a8fb1831776","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfe3cf3b4a1d4e6abb09bb7ee8e1820b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c2c4231c86b40ad8b8da9d1a079522e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import json, time \n","from tqdm import tqdm \n","from sklearn.metrics import f1_score, classification_report\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#bert_path = 'bert_model/' #该文件夹下存放三个文件（'vocab.txt', 'pytorch_model.bin', 'config.json'）\n","# 初始化tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case = False)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1643254065207,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"OmXL9o47bjvp"},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","set_seed(123)"]},{"cell_type":"markdown","metadata":{},"source":["小样本数据处理 data_helper"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","data process\n","\"\"\"\n","\n","import os\n","import json\n","import random\n","import copy\n","from collections import Counter\n","from itertools import chain\n","from typing import Dict, Tuple, Optional, List, Union\n","from transformers import RobertaTokenizer\n","import gensim\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","# 初始化tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case = False)\n","\n","class InductionData(object):\n","    def __init__(self, sequence_length = 256, num_classes = 5, num_support = 10,\n","                 num_queries = 50, num_tasks = 1000, num_eval_tasks = 100):\n","        \"\"\"\n","        init method\n","        :param num_classes: number of support class\n","        :param num_support: number of support sample per class\n","        :param num_queries: number of query sample per class\n","        :param num_tasks: number of pre-sampling tasks, this will speeding up train\n","        :param num_eval_tasks: number of pre-sampling tasks in eval stage\n","        \"\"\"\n","        self.__sequence_length = sequence_length\n","        self.__num_classes = num_classes\n","        self.__num_support = num_support\n","        self.__num_queries = num_queries\n","        self.__num_tasks = num_tasks\n","        self.__num_eval_tasks = num_eval_tasks\n","\n","\n","    def load_data(data_path):\n","        \"\"\"\n","        read train_set/eval_set/test_set\n","        :param data_path:\n","        :return: {file_name: {label: dataframe, ...}, ...}\n","        \"\"\"\n","        category_files = os.listdir(data_path)\n","        categories_data = {}\n","\n","        for category_file in category_files:\n","            file_path = os.path.join(data_path, category_file)\n","            sentiment_data = {}\n","            with open(file_path, \"r\", encoding=\"utf8\") as fr:\n","                for line in fr.readlines():\n","                    temp = list(line.strip().split(\"\\t\"))[-1]\n","                    cls = temp.split(',')[0]\n","                    sent = ' '.join([cls, temp[len(cls)+2:-1]])\n","                    sent = sent.strip()\n","                    label = int(temp[-1])\n","                    \n","                    # 随机拆分成两组标签\n","                    if label % 2 == 0:\n","                        label1 = label // 2\n","                    elif label == 1:\n","                        label1 = random.randint(0,1)\n","                    else:\n","                        label1 = random.randint(1,2)\n","                    label2 = label - label1\n","\n","                    encoded_dict = tokenizer.encode_plus(\n","                                text = sent,          # 输入文本\n","                                add_special_tokens = True,   # 添加'[CLS]'和'[SEP]'\n","                                max_length = self.__sequence_length,       # 填充/截断长度\n","                                padding = 'max_length',\n","                                truncation = True\n","                            )\n","                    input_ids = encoded_dict['input_ids']\n","                    input_masks = encoded_dict['attention_mask']\n","\n","                    content = {}\n","                    if sentiment_data.get(label, None):\n","                        sentiment_data[label]['sent'].append(sent)\n","                        sentiment_data[label]['ids'].append(input_ids)\n","                        sentiment_data[label]['masks'].append(input_masks)\n","                        sentiment_data[label]['label1'].append(label1)\n","                        sentiment_data[label]['label2'].append(label2)\n","                    else:\n","                        sentiment_data[label] = {}\n","                        sentiment_data[label]['sent'] = [sent]\n","                        sentiment_data[label]['ids'] = [input_ids]\n","                        sentiment_data[label]['masks'] = [input_masks]\n","                        sentiment_data[label]['label1'] = [label1]\n","                        sentiment_data[label]['label2'] = [label2]\n","            \n","\n","            print(\"task name: \", category_file)\n","            for i in range(5):\n","                # 每类的样本整合\n","                sentiment_data[i] = pd.DataFrame(sentiment_data[i])\n","                print(i, \"pos samples length: \", sentiment_data[i].shape[0])\n","            categories_data[category_file] = sentiment_data\n","        return categories_data\n","\n","    def choice_support_query(self, task_data):\n","        \"\"\"\n","        randomly selecting support set, query set form a task.\n","        :param task_data: all data for a task\n","        \"\"\"\n","        support_ids = []  # [num_classes, num_support, ]\n","        support_masks = []\n","        support_label1 = []\n","        suuport_label2 = []\n","\n","        query_ids = []  # [num_classes * num_queries, ]\n","        query_masks = []\n","        labels = []\n","\n","        # 每类不放回抽样\n","        for i in range(5):\n","            samples_i = task_data[i]\n","            all_idx = list(range(len(samples_i)))\n","            s_idx = np.random.choice(np.array(all_idx), self.__num_support, replace=False)\n","            support_i = samples_i.loc[s_idx, :]\n","\n","            \n","            [all_idx.remove(k) for k in s_idx.tolist()]\n","            query_idx = np.random.choice(np.array(all_idx), self.__num_queries, replace=False)\n","            query_i = samples_i.loc[query_idx, :]\n","\n","            support_ids.append(support_i.ids.tolist())\n","            support_masks.append(support_i.masks.tolist())\n","            support_label1.append(support_i.label1.tolist())\n","            support_label2.append(support_i.label2.tolist())\n","\n","            query_ids += query_i.ids.tolist()\n","            query_masks += query_i.masks.tolist()\n","            labels += [i*len(query_i)]\n","        support_set = TensorDataset(torch.LongTensor(support_ids),\n","                        torch.LongTensor(support_masks),\n","                        torch.LongTensor(support_label1),\n","                        torch.LongTensor(support_labels2))\n","        query_set = TensorDataset(torch.LongTensor(query_ids),\n","                        torch.LongTensor(query_masks))\n","        labels = TensorDataset(torch.LongTensor(labels))\n","\n","        return support_set, query_set, labels\n","\n","    def samples(self, data, f_name, is_training):\n","        \"\"\"\n","        c_class sample from raw data\n","        \"\"\"\n","        tasks = []\n","        if is_training:\n","            num_tasks = self.__num_tasks\n","        else:\n","            num_tasks = self.__num_eval_tasks\n","        for i in range(num_tasks):\n","            # use train_set to construct train sample\n","            # if eval: k=1, if test: k=2\n","            support_category = category_list[f_name]\n","            support_set, query_set, labels = self.choice_support_query(data[support_category])\n","            tasks.append(dict(support=support_set, queries=query_set, labels=labels))\n","        return tasks\n","\n","    def next_batch(self, data, f_name, is_training):\n","        \"\"\"\n","        train a task at every turn\n","        \"\"\"\n","\n","        tasks = self.samples(data, f_name, is_training)\n","\n","        for task in tasks:\n","            yield task\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_obj = InductionData()\n","data = data_obj.load_data('./dontpatronizeme_pcl/')\n","#train:\n","for train_batch in data_obj.next_batch(data, f_name = 'train_set.pcl.csv', is_training = True):\n","\n","#eval:\n","for eval_batch in data_obj.next_batch(data, f_name = 'val_set.pcl.csv', is_training = False):\n","\n","#test:\n","for test_batch in data_obj.next_batch(data, f_name = 'test_set.pcl.csv', is_training = False):"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":329,"status":"ok","timestamp":1643254080094,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"9lR2OQHXA7YQ"},"outputs":[],"source":["# Model with extra layers on top of Roberta\n","class Roberta_Model(nn.Module):\n","  def __init__(self, bert_path, classes = 5):\n","    super(Roberta_Model, self).__init__()\n","    self.roberta = RobertaModel.from_pretrained(bert_path)\n","    self.c1 = nn.Linear(768, 768)\n","    self.c2 = nn.Linear(768, 768)\n","    self.l1 = nn.Linear(768, 3)\n","    self.l2 = nn.Linear(768, 3)\n","    self.fc = nn.Linear(3*2, classes)\n","\n","  def forward(self, input_ids, attention_masks=None):\n","    outputs = self.roberta(input_ids, attention_masks)\n","    out_pool = outputs[1]\n","    # try: 拉开输入到分类器的embedding差距\n","    linear1 = self.c1(out_pool)\n","    linear2 = self.c2(out_pool)\n","\n","    logit1 = self.l1(linear1)\n","    logit2 = self.l2(linear2)\n","    context_combine = torch.cat((logit1, logit2), dim=-1)\n","    # 五分类\n","    logits = self.fc(context_combine)\n","    return logit1, logit2, logits"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139,"referenced_widgets":["a7e4e46335334fd4bcd5480cee4ffe66","078c43b622f146dea004e10128894c5b","a46213fa230b4440a20818e428881ef5","5f6ed3a29f2f430a84b21c7ed772642b","c9a8f22641b243b0a3bb807bbca77276","563121abafad4d5b9a6961199b926aa5","37a09fdd5b424bcfb14a58eb7b5c34ae","4296f3485b2949cdb30cfcf2c69c6972","326bfb69f37c49c8b17cd10ad6ee59d3","4797a265b5ce468fac584a20301e9455","4787e1475e0e49c7a358fc8ba23c2efe"]},"executionInfo":{"elapsed":23149,"status":"ok","timestamp":1643254104996,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"V_u6G1I5BUbs","outputId":"55df0bce-0ea5-4993-a8b5-09a893cf3f13"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7e4e46335334fd4bcd5480cee4ffe66","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Total parameters: 124645632, Trainable parameters: 124645632\n"]}],"source":["# 从预训练模型实例化BertForSequenceClassification\n","def get_parameter_number(model):\n","    #  打印模型参数量级\n","    total_num = sum(p.numel() for p in model.roberta.parameters())\n","    trainable_num = sum(p.numel() for p in model.roberta.parameters() if p.requires_grad)\n","    return 'Total parameters: {}, Trainable parameters: {}'.format(total_num, trainable_num)\n","\n","model = Roberta_Model('roberta-base').to(device)\n","print(get_parameter_number(model))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1643254254037,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"aklQpuwtxKL2"},"outputs":[],"source":["epochs = 100\n","# 定义AdamW优化器\n","optimizer = AdamW(model.parameters(), lr = 2e-5)\n","# 学习率调度器: 线性warmup一个epoch，再线性下降\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                      num_warmup_steps=len(train_loader),\n","                      num_training_steps=epochs*len(train_loader))\n","\n","# 定义评估指标F1(Macro F1 & Micro F1)\n","def F1_Score(preds, labels, average):\n","  \"\"\"\n","  average = 'macro'/'micro'\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return f1_score(pred_flat, labels_flat, average=average)\n"]},{"cell_type":"markdown","metadata":{"id":"oiFbeT07c5_X"},"source":["几种损失函数"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":338,"status":"ok","timestamp":1643254257731,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"XsgqsQiacDkr"},"outputs":[],"source":["#=====================Focal Loss===============================#\n","from torch.autograd import Variable\n","class FocalLoss(nn.Module):\n","    \"\"\"\n","        This criterion is a implemenation of Focal Loss, which is proposed in \n","        Focal Loss for Dense Object Detection.\n","\n","            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n","\n","        The losses are averaged across observations for each minibatch.\n","\n","        Args:\n","            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n","            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5), \n","                                   putting more focus on hard, misclassiﬁed examples\n","            size_average(bool): By default, the losses are averaged over observations for each minibatch.\n","                                However, if the field size_average is set to False, the losses are\n","                                instead summed for each minibatch.\n","\n","\n","    \"\"\"\n","    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        if alpha is None:\n","            self.alpha = Variable(torch.ones(class_num, 1))\n","        else:\n","            if isinstance(alpha, Variable):\n","                self.alpha = alpha\n","            else:\n","                self.alpha = Variable(alpha)\n","        self.gamma = gamma\n","        self.class_num = class_num\n","        self.size_average = size_average\n","\n","    def forward(self, inputs, targets):\n","        N = inputs.size(0)\n","        C = inputs.size(1)\n","        P = F.softmax(inputs)\n","\n","        class_mask = inputs.data.new(N, C).fill_(0)\n","        class_mask = Variable(class_mask)\n","        ids = targets.view(-1, 1)\n","        class_mask.scatter_(1, ids.data, 1.)\n","        #print(class_mask)\n","\n","\n","        if inputs.is_cuda and not self.alpha.is_cuda:\n","            self.alpha = self.alpha.cuda()\n","        alpha = self.alpha[ids.data.view(-1)]\n","\n","        probs = (P*class_mask).sum(1).view(-1,1)\n","\n","        log_p = probs.log()\n","        #print('probs size= {}'.format(probs.size()))\n","        #print(probs)\n","\n","        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n","        #print('-----bacth_loss------')\n","        #print(batch_loss)\n","\n","\n","        if self.size_average:\n","            loss = batch_loss.mean()\n","        else:\n","            loss = batch_loss.sum()\n","        return loss"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1643254259480,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"TMzEorgvc9K4"},"outputs":[],"source":["#=====================Dice Loss===============================#\n","class BinaryDiceLoss(nn.Module):\n","  def __init__(self):\n","    super(BinaryDiceLoss, self).__init__()\n","\t\n","  def forward(self, input, target):\n","    N = target.size(0)\n","    smooth = 1\n","\n","    input_flat = input.view(N, -1)\n","    target_flat = target.view(N, -1)\n","\n","    intersection = input_flat * target_flat\n","\n","    dice_eff = (2*intersection.sum(1) + smooth) / (input_flat.sum(1) + target_flat.sum(1) + smooth)\n","    loss = 1 - dice_eff.sum() / N\n","    return loss\n","\n","class DiceLoss(nn.Module):\n","  \"\"\"Dice loss\n","  Args:\n","      predict: A tensor of shape [N, C, *]\n","      target: A tensor of same shape with predict\n","  Return:\n","      same as BinaryDiceLoss\n","  \"\"\"\n","  def __init__(self):\n","    super(DiceLoss, self).__init__()\n","\n","  def forward(self, predict, target):\n","    target = F.one_hot(target.long(), predict.shape[1])\n","    assert predict.shape == target.shape, 'predict & target shape do not match'\n","    dice = BinaryDiceLoss()\n","    total_loss = 0\n","    predict = F.softmax(predict, dim=1)\n","\n","    for i in range(predict.shape[1]):\n","      dice_loss = dice(predict[:, i], target[:, i])\n","      total_loss += dice_loss\n","\n","    return total_loss/predict.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"TkIb8u4viE85"},"source":["早停策略"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1643254262418,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"yvwF-ZNFiHl-"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1643254264146,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"w3qyHaiBA04G"},"outputs":[],"source":["# 定义验证集评估函数\n","def evaluate(model, data_loader, device):\n","  # 设置模型为评估模式 (主要针对BN层 & DropOut层)\n","  model.eval()\n","  #criterion = nn.CrossEntropyLoss()\n","  criterion1 = FocalLoss(3)\n","  criterion2 = FocalLoss(5)\n","  criterion3 = DiceLoss()\n","  # Tracking variables\n","  total_f1_macro = 0\n","  total_f1_micro = 0\n","  total_loss = 0\n","  with torch.no_grad():\n","    for idx, (ids, masks, labels, labels_1, labels_2) in enumerate(data_loader):\n","      # batch inputs加载到gpu中\n","      ids = ids.to(device)\n","      masks = masks.to(device)\n","      labels = labels.to(device)\n","      labels_1 = labels_1.to(device)\n","      labels_2 = labels_2.to(device)\n","\n","      logits_1, logits_2, logits = model(ids, masks)\n","      loss = 0.4*criterion2(logits, labels) + 0.6*criterion1(logits_1, labels_1) + 0.6*criterion1(logits_2, labels_2)\n","      # 累加loss\n","      total_loss += loss.item()\n","      # 将y_pred和标签加载到cpu中计算\n","      y_pred = logits.detach().cpu().numpy()\n","      y = labels.to('cpu').numpy()\n","      # 计算F1准确率\n","      total_f1_macro += F1_Score(y_pred, y, 'macro')\n","      total_f1_micro += F1_Score(y_pred, y, 'micro')\n","\n","  avg_f1_macro = total_f1_macro / len(data_loader)\n","  avg_f1_micro = total_f1_micro / len(data_loader)\n","  avg_loss = total_loss / len(data_loader)\n","  return avg_f1_macro, avg_f1_micro, avg_loss\n","\n","# 定义预测函数\n","def predict(model, data_loader, device):\n","  model.eval()\n","  y_preds = []\n","  with torch.no_grad():\n","    for idx, (ids, masks) in enumerate(data_loader):\n","      _, _, logits = model(ids.to(device), masks.to(device))\n","      y_pred = torch.argmax(logits, dim=1).detach().cpu().numpy().tolist()\n","      y_preds.extend(y_pred)\n","  return y_preds"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":489,"status":"ok","timestamp":1643254265877,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"jyyjbkcK0Cmi"},"outputs":[],"source":["# 计时器设置\n","import time\n","import datetime\n","def format_time(elapsed):\n","  \"\"\"\n","  Takes a time in seconds and return a string hh:mm:ss\n","  \"\"\"\n","  elapsed_rounded = int(round(elapsed))\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1643254267263,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"HkI9NUqLANGu"},"outputs":[],"source":["def train(model, \n","      train_loader, \n","      val_loader,\n","      optimizer,\n","      scheduler,\n","      device,\n","      epochs):\n","  \"\"\"\n","  Train the ROBERTa model\n","  \"\"\"\n","  #criterion = nn.CrossEntropyLoss()\n","  criterion1 = FocalLoss(3)\n","  criterion2 = FocalLoss(5)\n","  criterion3 = DiceLoss()\n","  best_f1_macro = 0.0\n","  # set early stopping\n","  early_stopping = EarlyStopping(patience=20, verbose=True)\n","  # 整体训练时长\n","  total_t0 = time.time()\n","\n","  for i in range(epochs):\n","    ##########################################\n","    #        Training        #\n","    ##########################################\n","    print(\"******** Running training epoch {:}/{:} ********\".format(i+1, epochs))\n","    \n","    t0 = time.time()  \n","    model.train()    \n","    train_loss_sum = 0.0\n","    \n","    for step, (ids, masks, labels, labels_1, labels_2) in enumerate(train_loader):\n","      ids = ids.to(device)\n","      masks = masks.to(device)\n","      labels = labels.to(device)\n","      labels_1 = labels_1.to(device)\n","      labels_2 = labels_2.to(device)\n","      \n","      optimizer.zero_grad()         # 梯度初始化为零\n","      logits_1, logits_2, logits = model(ids, masks) # forward\n","      loss = 0.4*criterion2(logits, labels) + 0.6*criterion1(logits_1, labels_1) + 0.6*criterion1(logits_2, labels_2)\n","      train_loss_sum += loss.item()\n","\n","      loss.backward()                   # backward\n","      nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 梯度剪裁\n","      optimizer.step()                   # 更新参数\n","      scheduler.step()                   # 更新学习率\n","\n","      # 经过 len(train_loader)//5 次迭代, 打印进度条\n","      if (step+1) % (len(train_loader)//5) == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print(\"   Epoch {:} | Step {:}/{:} | Loss {:.4f} | Time {:}\".\\\n","              format(i+1, step+1, len(train_loader), train_loss_sum/(step+1), elapsed))\n","    \n","    train_loss_avg = train_loss_sum / len(train_loader)\n","    epoch_time = format_time(time.time() - t0)\n","    print(\"\")\n","    print(\"   Average training loss: {:.4f}\".format(train_loss_avg))\n","    print(\"   Training epoch time: {:}\".format(epoch_time))\n","\n","    ##########################################\n","    #               Validation               #\n","    ##########################################\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    t0 = time.time()\n","    model.eval()\n","    val_f1_macro, val_f1_micro, val_loss = evaluate(model, val_loader, device)\n","    val_time = format_time(time.time()-t0)\n","\n","    if val_f1_macro > best_f1_macro:\n","      best_f1_macro = val_f1_macro\n","      torch.save(model.state_dict(), \"best_roberta_model.pth\")\n","\n","    print(\"   F1_macro: {:.2f}\".format(val_f1_macro))\n","    print(\"   F1_micro: {:.2f}\".format(val_f1_micro))\n","    print(\"   Validation Loss: {:.4f}\".format(val_loss))\n","    print(\"   Validation time: {:}\".format(val_time))\n","\n","    # early_stopping needs the validation loss to check if it has decresed, \n","    # and if it has, it will make a checkpoint of the current model\n","    early_stopping(val_loss, model)\n","    \n","    if early_stopping.early_stop:\n","        print(\"Early stopping\")\n","        break\n","  \n","  print(\"\")\n","  print(\"Training completed!\")\n","  print(\"Total training time: {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8996149,"status":"ok","timestamp":1643263264913,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"Qrtc4Oj3V5UQ","outputId":"9f676d91-34d4-46f0-982e-2c9f658b845f"},"outputs":[{"name":"stdout","output_type":"stream","text":["******** Running training epoch 1/100 ********\n","   Epoch 1 | Step 69/349 | Loss 1.0290 | Time 0:01:12\n","   Epoch 1 | Step 138/349 | Loss 0.8408 | Time 0:02:25\n","   Epoch 1 | Step 207/349 | Loss 0.7395 | Time 0:03:39\n","   Epoch 1 | Step 276/349 | Loss 0.6658 | Time 0:04:53\n","   Epoch 1 | Step 345/349 | Loss 0.6151 | Time 0:06:07\n","\n","   Average training loss: 0.6127\n","   Training epoch time: 0:06:11\n","\n","Running Validation...\n","   F1_macro: 0.38\n","   F1_micro: 0.74\n","   Validation Loss: 0.3912\n","   Validation time: 0:00:16\n","Validation loss decreased (inf --> 0.391211).  Saving model ...\n","******** Running training epoch 2/100 ********\n","   Epoch 2 | Step 69/349 | Loss 0.4384 | Time 0:01:14\n","   Epoch 2 | Step 138/349 | Loss 0.4151 | Time 0:02:28\n","   Epoch 2 | Step 207/349 | Loss 0.3933 | Time 0:03:42\n","   Epoch 2 | Step 276/349 | Loss 0.3836 | Time 0:04:56\n","   Epoch 2 | Step 345/349 | Loss 0.3801 | Time 0:06:10\n","\n","   Average training loss: 0.3804\n","   Training epoch time: 0:06:14\n","\n","Running Validation...\n","   F1_macro: 0.35\n","   F1_micro: 0.80\n","   Validation Loss: 0.3839\n","   Validation time: 0:00:16\n","Validation loss decreased (0.391211 --> 0.383928).  Saving model ...\n","******** Running training epoch 3/100 ********\n","   Epoch 3 | Step 69/349 | Loss 0.2976 | Time 0:01:14\n","   Epoch 3 | Step 138/349 | Loss 0.2897 | Time 0:02:28\n","   Epoch 3 | Step 207/349 | Loss 0.2820 | Time 0:03:42\n","   Epoch 3 | Step 276/349 | Loss 0.2749 | Time 0:04:55\n","   Epoch 3 | Step 345/349 | Loss 0.2733 | Time 0:06:09\n","\n","   Average training loss: 0.2748\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.39\n","   F1_micro: 0.80\n","   Validation Loss: 0.3631\n","   Validation time: 0:00:16\n","Validation loss decreased (0.383928 --> 0.363087).  Saving model ...\n","******** Running training epoch 4/100 ********\n","   Epoch 4 | Step 69/349 | Loss 0.1939 | Time 0:01:14\n","   Epoch 4 | Step 138/349 | Loss 0.2020 | Time 0:02:28\n","   Epoch 4 | Step 207/349 | Loss 0.1957 | Time 0:03:42\n","   Epoch 4 | Step 276/349 | Loss 0.1969 | Time 0:04:55\n","   Epoch 4 | Step 345/349 | Loss 0.1946 | Time 0:06:09\n","\n","   Average training loss: 0.1942\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.38\n","   F1_micro: 0.79\n","   Validation Loss: 0.4045\n","   Validation time: 0:00:16\n","EarlyStopping counter: 1 out of 20\n","******** Running training epoch 5/100 ********\n","   Epoch 5 | Step 69/349 | Loss 0.1395 | Time 0:01:14\n","   Epoch 5 | Step 138/349 | Loss 0.1527 | Time 0:02:27\n","   Epoch 5 | Step 207/349 | Loss 0.1500 | Time 0:03:41\n","   Epoch 5 | Step 276/349 | Loss 0.1501 | Time 0:04:55\n","   Epoch 5 | Step 345/349 | Loss 0.1503 | Time 0:06:09\n","\n","   Average training loss: 0.1504\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.38\n","   F1_micro: 0.79\n","   Validation Loss: 0.5225\n","   Validation time: 0:00:16\n","EarlyStopping counter: 2 out of 20\n","******** Running training epoch 6/100 ********\n","   Epoch 6 | Step 69/349 | Loss 0.1288 | Time 0:01:14\n","   Epoch 6 | Step 138/349 | Loss 0.1262 | Time 0:02:28\n","   Epoch 6 | Step 207/349 | Loss 0.1288 | Time 0:03:41\n","   Epoch 6 | Step 276/349 | Loss 0.1261 | Time 0:04:55\n","   Epoch 6 | Step 345/349 | Loss 0.1298 | Time 0:06:09\n","\n","   Average training loss: 0.1302\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.41\n","   F1_micro: 0.80\n","   Validation Loss: 0.4886\n","   Validation time: 0:00:16\n","EarlyStopping counter: 3 out of 20\n","******** Running training epoch 7/100 ********\n","   Epoch 7 | Step 69/349 | Loss 0.1173 | Time 0:01:14\n","   Epoch 7 | Step 138/349 | Loss 0.1125 | Time 0:02:28\n","   Epoch 7 | Step 207/349 | Loss 0.1100 | Time 0:03:42\n","   Epoch 7 | Step 276/349 | Loss 0.1113 | Time 0:04:55\n","   Epoch 7 | Step 345/349 | Loss 0.1116 | Time 0:06:09\n","\n","   Average training loss: 0.1112\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.41\n","   F1_micro: 0.79\n","   Validation Loss: 0.5385\n","   Validation time: 0:00:16\n","EarlyStopping counter: 4 out of 20\n","******** Running training epoch 8/100 ********\n","   Epoch 8 | Step 69/349 | Loss 0.0984 | Time 0:01:14\n","   Epoch 8 | Step 138/349 | Loss 0.0963 | Time 0:02:28\n","   Epoch 8 | Step 207/349 | Loss 0.0981 | Time 0:03:42\n","   Epoch 8 | Step 276/349 | Loss 0.0989 | Time 0:04:56\n","   Epoch 8 | Step 345/349 | Loss 0.0981 | Time 0:06:10\n","\n","   Average training loss: 0.0979\n","   Training epoch time: 0:06:14\n","\n","Running Validation...\n","   F1_macro: 0.41\n","   F1_micro: 0.80\n","   Validation Loss: 0.5690\n","   Validation time: 0:00:16\n","EarlyStopping counter: 5 out of 20\n","******** Running training epoch 9/100 ********\n","   Epoch 9 | Step 69/349 | Loss 0.0906 | Time 0:01:14\n","   Epoch 9 | Step 138/349 | Loss 0.0883 | Time 0:02:28\n","   Epoch 9 | Step 207/349 | Loss 0.0954 | Time 0:03:41\n","   Epoch 9 | Step 276/349 | Loss 0.0911 | Time 0:04:55\n","   Epoch 9 | Step 345/349 | Loss 0.0912 | Time 0:06:09\n","\n","   Average training loss: 0.0907\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.40\n","   F1_micro: 0.79\n","   Validation Loss: 0.6334\n","   Validation time: 0:00:16\n","EarlyStopping counter: 6 out of 20\n","******** Running training epoch 10/100 ********\n","   Epoch 10 | Step 69/349 | Loss 0.0787 | Time 0:01:14\n","   Epoch 10 | Step 138/349 | Loss 0.0901 | Time 0:02:27\n","   Epoch 10 | Step 207/349 | Loss 0.0837 | Time 0:03:41\n","   Epoch 10 | Step 276/349 | Loss 0.0842 | Time 0:04:55\n","   Epoch 10 | Step 345/349 | Loss 0.0839 | Time 0:06:09\n","\n","   Average training loss: 0.0837\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.43\n","   F1_micro: 0.79\n","   Validation Loss: 0.6403\n","   Validation time: 0:00:16\n","EarlyStopping counter: 7 out of 20\n","******** Running training epoch 11/100 ********\n","   Epoch 11 | Step 69/349 | Loss 0.0690 | Time 0:01:14\n","   Epoch 11 | Step 138/349 | Loss 0.0738 | Time 0:02:28\n","   Epoch 11 | Step 207/349 | Loss 0.0786 | Time 0:03:41\n","   Epoch 11 | Step 276/349 | Loss 0.0760 | Time 0:04:55\n","   Epoch 11 | Step 345/349 | Loss 0.0737 | Time 0:06:09\n","\n","   Average training loss: 0.0741\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.39\n","   F1_micro: 0.75\n","   Validation Loss: 0.6318\n","   Validation time: 0:00:16\n","EarlyStopping counter: 8 out of 20\n","******** Running training epoch 12/100 ********\n","   Epoch 12 | Step 69/349 | Loss 0.0738 | Time 0:01:14\n","   Epoch 12 | Step 138/349 | Loss 0.0739 | Time 0:02:28\n","   Epoch 12 | Step 207/349 | Loss 0.0696 | Time 0:03:42\n","   Epoch 12 | Step 276/349 | Loss 0.0695 | Time 0:04:55\n","   Epoch 12 | Step 345/349 | Loss 0.0690 | Time 0:06:09\n","\n","   Average training loss: 0.0699\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.41\n","   F1_micro: 0.81\n","   Validation Loss: 0.7983\n","   Validation time: 0:00:16\n","EarlyStopping counter: 9 out of 20\n","******** Running training epoch 13/100 ********\n","   Epoch 13 | Step 69/349 | Loss 0.0485 | Time 0:01:14\n","   Epoch 13 | Step 138/349 | Loss 0.0500 | Time 0:02:28\n","   Epoch 13 | Step 207/349 | Loss 0.0527 | Time 0:03:42\n","   Epoch 13 | Step 276/349 | Loss 0.0513 | Time 0:04:56\n","   Epoch 13 | Step 345/349 | Loss 0.0506 | Time 0:06:09\n","\n","   Average training loss: 0.0503\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.40\n","   F1_micro: 0.79\n","   Validation Loss: 0.7594\n","   Validation time: 0:00:16\n","EarlyStopping counter: 10 out of 20\n","******** Running training epoch 14/100 ********\n","   Epoch 14 | Step 69/349 | Loss 0.0484 | Time 0:01:14\n","   Epoch 14 | Step 138/349 | Loss 0.0459 | Time 0:02:27\n","   Epoch 14 | Step 207/349 | Loss 0.0431 | Time 0:03:41\n","   Epoch 14 | Step 276/349 | Loss 0.0462 | Time 0:04:55\n","   Epoch 14 | Step 345/349 | Loss 0.0446 | Time 0:06:09\n","\n","   Average training loss: 0.0449\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.40\n","   F1_micro: 0.78\n","   Validation Loss: 0.8024\n","   Validation time: 0:00:16\n","EarlyStopping counter: 11 out of 20\n","******** Running training epoch 15/100 ********\n","   Epoch 15 | Step 69/349 | Loss 0.0346 | Time 0:01:14\n","   Epoch 15 | Step 138/349 | Loss 0.0358 | Time 0:02:27\n","   Epoch 15 | Step 207/349 | Loss 0.0327 | Time 0:03:41\n","   Epoch 15 | Step 276/349 | Loss 0.0342 | Time 0:04:55\n","   Epoch 15 | Step 345/349 | Loss 0.0350 | Time 0:06:09\n","\n","   Average training loss: 0.0347\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.39\n","   F1_micro: 0.78\n","   Validation Loss: 0.8722\n","   Validation time: 0:00:16\n","EarlyStopping counter: 12 out of 20\n","******** Running training epoch 16/100 ********\n","   Epoch 16 | Step 69/349 | Loss 0.0326 | Time 0:01:14\n","   Epoch 16 | Step 138/349 | Loss 0.0287 | Time 0:02:27\n","   Epoch 16 | Step 207/349 | Loss 0.0289 | Time 0:03:41\n","   Epoch 16 | Step 276/349 | Loss 0.0307 | Time 0:04:55\n","   Epoch 16 | Step 345/349 | Loss 0.0316 | Time 0:06:09\n","\n","   Average training loss: 0.0317\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.38\n","   F1_micro: 0.79\n","   Validation Loss: 0.8851\n","   Validation time: 0:00:16\n","EarlyStopping counter: 13 out of 20\n","******** Running training epoch 17/100 ********\n","   Epoch 17 | Step 69/349 | Loss 0.0273 | Time 0:01:14\n","   Epoch 17 | Step 138/349 | Loss 0.0219 | Time 0:02:27\n","   Epoch 17 | Step 207/349 | Loss 0.0214 | Time 0:03:41\n","   Epoch 17 | Step 276/349 | Loss 0.0208 | Time 0:04:55\n","   Epoch 17 | Step 345/349 | Loss 0.0205 | Time 0:06:09\n","\n","   Average training loss: 0.0208\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.39\n","   F1_micro: 0.77\n","   Validation Loss: 1.0022\n","   Validation time: 0:00:16\n","EarlyStopping counter: 14 out of 20\n","******** Running training epoch 18/100 ********\n","   Epoch 18 | Step 69/349 | Loss 0.0287 | Time 0:01:14\n","   Epoch 18 | Step 138/349 | Loss 0.0234 | Time 0:02:28\n","   Epoch 18 | Step 207/349 | Loss 0.0218 | Time 0:03:41\n","   Epoch 18 | Step 276/349 | Loss 0.0207 | Time 0:04:55\n","   Epoch 18 | Step 345/349 | Loss 0.0193 | Time 0:06:09\n","\n","   Average training loss: 0.0191\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.40\n","   F1_micro: 0.77\n","   Validation Loss: 0.9773\n","   Validation time: 0:00:16\n","EarlyStopping counter: 15 out of 20\n","******** Running training epoch 19/100 ********\n","   Epoch 19 | Step 69/349 | Loss 0.0093 | Time 0:01:14\n","   Epoch 19 | Step 138/349 | Loss 0.0101 | Time 0:02:28\n","   Epoch 19 | Step 207/349 | Loss 0.0115 | Time 0:03:41\n","   Epoch 19 | Step 276/349 | Loss 0.0131 | Time 0:04:55\n","   Epoch 19 | Step 345/349 | Loss 0.0136 | Time 0:06:09\n","\n","   Average training loss: 0.0135\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.41\n","   F1_micro: 0.78\n","   Validation Loss: 1.0065\n","   Validation time: 0:00:16\n","EarlyStopping counter: 16 out of 20\n","******** Running training epoch 20/100 ********\n","   Epoch 20 | Step 69/349 | Loss 0.0128 | Time 0:01:14\n","   Epoch 20 | Step 138/349 | Loss 0.0150 | Time 0:02:28\n","   Epoch 20 | Step 207/349 | Loss 0.0143 | Time 0:03:41\n","   Epoch 20 | Step 276/349 | Loss 0.0134 | Time 0:04:55\n","   Epoch 20 | Step 345/349 | Loss 0.0116 | Time 0:06:09\n","\n","   Average training loss: 0.0118\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.40\n","   F1_micro: 0.80\n","   Validation Loss: 1.0683\n","   Validation time: 0:00:16\n","EarlyStopping counter: 17 out of 20\n","******** Running training epoch 21/100 ********\n","   Epoch 21 | Step 69/349 | Loss 0.0132 | Time 0:01:14\n","   Epoch 21 | Step 138/349 | Loss 0.0090 | Time 0:02:28\n","   Epoch 21 | Step 207/349 | Loss 0.0147 | Time 0:03:41\n","   Epoch 21 | Step 276/349 | Loss 0.0138 | Time 0:04:55\n","   Epoch 21 | Step 345/349 | Loss 0.0121 | Time 0:06:09\n","\n","   Average training loss: 0.0119\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.44\n","   F1_micro: 0.79\n","   Validation Loss: 1.0531\n","   Validation time: 0:00:16\n","EarlyStopping counter: 18 out of 20\n","******** Running training epoch 22/100 ********\n","   Epoch 22 | Step 69/349 | Loss 0.0098 | Time 0:01:14\n","   Epoch 22 | Step 138/349 | Loss 0.0090 | Time 0:02:28\n","   Epoch 22 | Step 207/349 | Loss 0.0111 | Time 0:03:42\n","   Epoch 22 | Step 276/349 | Loss 0.0094 | Time 0:04:55\n","   Epoch 22 | Step 345/349 | Loss 0.0096 | Time 0:06:09\n","\n","   Average training loss: 0.0099\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.39\n","   F1_micro: 0.79\n","   Validation Loss: 1.0722\n","   Validation time: 0:00:16\n","EarlyStopping counter: 19 out of 20\n","******** Running training epoch 23/100 ********\n","   Epoch 23 | Step 69/349 | Loss 0.0044 | Time 0:01:14\n","   Epoch 23 | Step 138/349 | Loss 0.0090 | Time 0:02:27\n","   Epoch 23 | Step 207/349 | Loss 0.0101 | Time 0:03:41\n","   Epoch 23 | Step 276/349 | Loss 0.0119 | Time 0:04:55\n","   Epoch 23 | Step 345/349 | Loss 0.0120 | Time 0:06:09\n","\n","   Average training loss: 0.0119\n","   Training epoch time: 0:06:13\n","\n","Running Validation...\n","   F1_macro: 0.36\n","   F1_micro: 0.78\n","   Validation Loss: 1.0435\n","   Validation time: 0:00:16\n","EarlyStopping counter: 20 out of 20\n","Early stopping\n","\n","Training completed!\n","Total training time: 2:29:56 (h:mm:ss)\n"]}],"source":["train(model, train_loader, val_loader, optimizer, scheduler, device, epochs)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17885,"status":"ok","timestamp":1643263385373,"user":{"displayName":"yanjie zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13657585540825437055"},"user_tz":-480},"id":"KGCoR2RvWPMS","outputId":"af24e6a7-355c-4f5a-b15c-ba643ba04dd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_F1_macro: 0.42\n","test_F1_micro: 0.79\n"]}],"source":["# 加载最优模型进行测试\n","model.load_state_dict(torch.load(\"best_roberta_model.pth\"))\n","test_pred = predict(model, test_loader, device)\n","test_labels = test_df.labels\n","\n","test_f1_macro = f1_score(test_pred, test_labels, average='macro')\n","test_f1_micro = f1_score(test_pred, test_labels, average='micro')\n","print(\"test_F1_macro: {:.2f}\".format(test_f1_macro))\n","print(\"test_F1_micro: {:.2f}\".format(test_f1_micro))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PAwIYWnQ3eJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"roberta_3_focal.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04a5034c9621451c9742d2862e22d0e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"078c43b622f146dea004e10128894c5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19519b2ac11e408b8d4ab5bf6feff9ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef29f1edc1d4cd6a5110f55de44d2d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28afab1a17be4198adb3de2ea49bff34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d3480c2224f413daa680734d6d8cbe1","IPY_MODEL_2f7595ed850241049a35a3e1a8fc0931","IPY_MODEL_ceba5575677c4132acf2e89da0ae4099"],"layout":"IPY_MODEL_911ba88c06a447e2a6d3100a35b8bfca"}},"29f3e99c2fbd484bbfc2f69caae97512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef29f1edc1d4cd6a5110f55de44d2d3","placeholder":"​","style":"IPY_MODEL_f97917f76466497c8a42c341cf4baadb","value":"Downloading: 100%"}},"2c2c4231c86b40ad8b8da9d1a079522e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa17a8b3e476417d934ef957519cf48a","IPY_MODEL_82a9518bdd8b4d7987c06749ce2a2353","IPY_MODEL_3cc882d6c19e44c699707dd859321a62"],"layout":"IPY_MODEL_337ed3cc8e994556a75fd1301626582a"}},"2f7595ed850241049a35a3e1a8fc0931":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3f95541da78493bbf3ef4ce430a27b0","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bf199bd414d4d1d890af5a1626ef03c","value":898823}},"3036522ca17944ee822d9a1b5414516e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"326bfb69f37c49c8b17cd10ad6ee59d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32e54826a0574939bfb1d08adc2bf971":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"337ed3cc8e994556a75fd1301626582a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3786a9827bed4cacb9c434d0b2416577":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a09fdd5b424bcfb14a58eb7b5c34ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38a1914c49194598b33e6e471f808463":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cc882d6c19e44c699707dd859321a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ecfbfaaaa8b48c78b3161d4143925bd","placeholder":"​","style":"IPY_MODEL_cd7c64d13f704ee093a797ef5854423e","value":" 481/481 [00:00&lt;00:00, 12.9kB/s]"}},"3d3480c2224f413daa680734d6d8cbe1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_749264fa8efa4c7fbb6cc1d98794ffd6","placeholder":"​","style":"IPY_MODEL_19519b2ac11e408b8d4ab5bf6feff9ba","value":"Downloading: 100%"}},"3fdd2080dee146fdafc1a16844120d9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea816ad46bcb4960ac42d5322b7b7be0","placeholder":"​","style":"IPY_MODEL_db888624c36a4efb94fc5dc0b4ef5b9f","value":"Downloading: 100%"}},"408b3fc6c2c045f4b04001745926b196":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38a1914c49194598b33e6e471f808463","placeholder":"​","style":"IPY_MODEL_900d4575e28f48ffabc5511d24a99bcb","value":" 446k/446k [00:00&lt;00:00, 889kB/s]"}},"4296f3485b2949cdb30cfcf2c69c6972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4787e1475e0e49c7a358fc8ba23c2efe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4797a265b5ce468fac584a20301e9455":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"563121abafad4d5b9a6961199b926aa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f6ed3a29f2f430a84b21c7ed772642b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_326bfb69f37c49c8b17cd10ad6ee59d3","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4296f3485b2949cdb30cfcf2c69c6972","value":501200538}},"670a568fac82495994a330ecdb64f0f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"749264fa8efa4c7fbb6cc1d98794ffd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"784aa229669b4e719776499cbc65423e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3786a9827bed4cacb9c434d0b2416577","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d5b0648699c44d0b355a2a643de414d","value":1355863}},"82042c072d63457e9c3849d7e8d19c7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82a9518bdd8b4d7987c06749ce2a2353":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e025491975004dcb91c12281fbb28a4b","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a22567d2d8d94b4b9bed8c01fccbc5a9","value":481}},"840e5e9e85084f1ebaf764f699128a24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf199bd414d4d1d890af5a1626ef03c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d5b0648699c44d0b355a2a643de414d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"900d4575e28f48ffabc5511d24a99bcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"911ba88c06a447e2a6d3100a35b8bfca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f301b942b14791a2f5cd5202eb5c03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97f238c6428542e190e69a83ae3855f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3036522ca17944ee822d9a1b5414516e","placeholder":"​","style":"IPY_MODEL_d8982909a80143088709ca6a5bf0baed","value":" 1.29M/1.29M [00:00&lt;00:00, 2.87MB/s]"}},"9ecfbfaaaa8b48c78b3161d4143925bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22567d2d8d94b4b9bed8c01fccbc5a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a46213fa230b4440a20818e428881ef5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37a09fdd5b424bcfb14a58eb7b5c34ae","placeholder":"​","style":"IPY_MODEL_563121abafad4d5b9a6961199b926aa5","value":"Downloading: 100%"}},"a7e4e46335334fd4bcd5480cee4ffe66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a46213fa230b4440a20818e428881ef5","IPY_MODEL_5f6ed3a29f2f430a84b21c7ed772642b","IPY_MODEL_c9a8f22641b243b0a3bb807bbca77276"],"layout":"IPY_MODEL_078c43b622f146dea004e10128894c5b"}},"a9a18fcaa83c4e44b58f636bcd5323d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3f95541da78493bbf3ef4ce430a27b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9a8f22641b243b0a3bb807bbca77276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4787e1475e0e49c7a358fc8ba23c2efe","placeholder":"​","style":"IPY_MODEL_4797a265b5ce468fac584a20301e9455","value":" 478M/478M [00:09&lt;00:00, 57.0MB/s]"}},"cd7c64d13f704ee093a797ef5854423e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceba5575677c4132acf2e89da0ae4099":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_670a568fac82495994a330ecdb64f0f7","placeholder":"​","style":"IPY_MODEL_da72526902ef4683aa89d9eb9965fab5","value":" 878k/878k [00:00&lt;00:00, 2.75MB/s]"}},"d3b883d5280d43f7bb835a8fb1831776":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29f3e99c2fbd484bbfc2f69caae97512","IPY_MODEL_f6693d4bd72f472ba1680ecfb02996fc","IPY_MODEL_408b3fc6c2c045f4b04001745926b196"],"layout":"IPY_MODEL_04a5034c9621451c9742d2862e22d0e5"}},"d8982909a80143088709ca6a5bf0baed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da72526902ef4683aa89d9eb9965fab5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db888624c36a4efb94fc5dc0b4ef5b9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfe3cf3b4a1d4e6abb09bb7ee8e1820b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fdd2080dee146fdafc1a16844120d9c","IPY_MODEL_784aa229669b4e719776499cbc65423e","IPY_MODEL_97f238c6428542e190e69a83ae3855f6"],"layout":"IPY_MODEL_840e5e9e85084f1ebaf764f699128a24"}},"e025491975004dcb91c12281fbb28a4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea816ad46bcb4960ac42d5322b7b7be0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6693d4bd72f472ba1680ecfb02996fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82042c072d63457e9c3849d7e8d19c7e","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9a18fcaa83c4e44b58f636bcd5323d2","value":456318}},"f97917f76466497c8a42c341cf4baadb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa17a8b3e476417d934ef957519cf48a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32e54826a0574939bfb1d08adc2bf971","placeholder":"​","style":"IPY_MODEL_93f301b942b14791a2f5cd5202eb5c03","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
